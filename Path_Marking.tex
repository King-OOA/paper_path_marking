\documentclass{article}


\usepackage{enumerate}

\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{color}
\newcommand{\SWITCH}[1]{\STATE \textbf{switch} (#1)}
\newcommand{\ENDPWITCH}{\STATE \textbf{end switch}}
\newcommand{\CASE}[1]{\STATE \textbf{case} #1\textbf{:} \begin{ALC@g}}
\newcommand{\ENDCASE}{\end{ALC@g}}
\newcommand{\CASELINE}[1]{\STATE \textbf{case} #1\textbf{:} }
\newcommand{\DEFAULT}{\STATE \textbf{default:} \begin{ALC@g}}
\newcommand{\ENDDEFAULT}{\end{ALC@g}}
\newcommand{\DEFAULTLINE}[1]{\STATE \textbf{default:} }
\newtheorem{mydef}{Definition}
\newtheorem{mylm}{Proposition}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}


\begin{document}


\title{A Efficient Exact Algorithm for Multiple Longest Common
  Subsequences (MLCS) Problem Based on Path Marking}

\author{Zhan Peng, Yuping Wang\footnote{Corresponding author}~,}


\maketitle

%begin{history}
%received{(Day Month Year)}
%revised{(Day Month Year)}
%accepted{(Day Month Year)}
%comby{(xxxxxxxxxx)}
%end{history}

\begin{abstract}

  Searching for the Multiple Longest Common Subsequences (MLCS) of
  multiple sequences is a classical NP-hard problem that is widely
  used in many areas such as bioinformatics and biomedicine,
  etc. Although significant efforts have been made to address this
  problem, the increasing amount of biological data require more
  efficient methods. In this paper, we present a novel fast algorithm
  for the MLCS problem, which is based on the dominant point approach
  and employs a new technique called path marking. During the
  construction of the dominant point graph, the path marking technique
  can real-timely mark the longest path from the source node to the
  current node, and once the graph has been constructed the longest
  paths corresponding to every MLCS can be found immediately. The
  experimental results demonstrate that, comparing with the ``Minima''
  operation that is widely used in the existing algorithms, the path
  marking is much more efficient, and therefore our algorithm is
  faster than those algorithms.

\end{abstract}

\textbf{multiple longest common subsequences (MLCS); Longest common
  subsequence (LCS); dominant point method}

% due to the effectiveness of the filter and the compactness of the AMT
% whether there are patterns starting at that position

\section{Introduction}
\label{sec:introduction}


Many kinds of biological data can be represented as a sequence of
symbols. For instance, proteins [2] are sequences over 20 different
symbols (amino acids), and DNA (genes) can be represented as sequences
over four symbols A, C, G and T corresponding to the four bases.
Measuring the similarity of biological sequences is a fundamental
problem in bioinformatics, which can be used in many applications such
as cancer diagnoses, detection of the species’ common origin [2],
etc. One of the most important ways to measure the similarity of
biological sequences is to find their Multiple Longest Common
Subsequences (MLCS), which has been proved to be an NP-hard problem []
. Traditionally, the works are focusing on either the simplest case of
two sequences, also known as the Longest Common Subsequences (LCS)
problem [24], [36], [39], [45], or the problem’s special case of
three sequences [21], [22]. Although many algorithms have been
proposed for the general case of the problem, they are not very
efficient in practice for large-size problems with many sequences due
to high time and space complexity. Particularly, with the successful
implementation of the human genome project and the development of the
next-generation sequencing techniques, the amount of biological
sequences (as well as other types of sequences from various fields)
are growing explosively [3]. Therefore, it is very important and
valuable to design more efficient MLCS algorithm to process large
amount of biological (and other types) sequences.

In this paper, we proposed a fast algorithm for finding MLCS of many
sequences. Our algorithm is based on the dominant point model, in
which the dominant points produced during processing are organized to
form a Directed Acyclic Graph (DAG), and each of the longest paths
from the source node to the end node corresponds to a MLCS. Different
from the other dominant point based algorithms that using a
time-consuming \emph{Minima} operation to delete the redundant nodes,
and then search for the longest paths from the source node to the end
node to find the MLCS, our method employs a technical called
\emph{path marking}, whenever a node is generated, the longest path
from the source node to the new node is updated immediately, and once
the DAG is constructed, all the MLCS can be found directly from the
end node back to the source node by the marked path. The experiments
shows that the \emph{path marking} technique is much efficient than
the \emph{Minima} operation, so that our algorithm is much faster than
the compared algorithms.

The this paper is organized as follows: Section \ref{sec:related
  works} introduces some preliminaries and reviews the related works
in the MLCS problem. Section \ref{sec:notations} lists the notations
and terminology used in this paper. In section \ref{sec:algorithm},
the our new algorithm is presented in details. In section
\ref{sec:experiments}, experimental results comparing the performances
of the new algorithms with existing ones are presented. In Section
\ref{sec:conclusion} we summarize the paper.

\section{Preliminaries and Related Works}
\label{sec:related works}

In this section, we define some notations and terminology used in this
paper and reviews some related works in the MLCS problem.

Let $\Sigma$ represent a finite alphabet for the sequences.  For
example, for the DNA sequences, $\Sigma=\{A, C, T, G\}$.

\textbf{Definition 1.} Let $s=c_1c_2...c_n$ be a sequence with length
$n$ over $\Sigma$. A \emph{subsequence} of $s$ is the one that can be
obtained by deleting zero or more (not necessarily consecutive)
characters from $s$. Formally, $s'=c_{i_1}c_{i_2}...c_{i_k}$ is called
a subsequence of $s$, if for $1 \leq j \leq k$, there is
$1 \leq i_j \leq n$, and for all $r$ and $t$, $1 \leq r < t \leq k$,
there is $i_r < i_t$.\\

\textbf{Definition 2.} Let $S=\{s_1, s_2, ..., s_d\}$ be a set of $d$
sequences over $\Sigma$. A Longest Common Subsequence (\emph{LCS}) of
$S$ is a sequence $lcs$ such that: (1) $lcs$ is a subsequence of all
$s_i$ ($1 \leq i \leq d$); (2) there is no sequence satisfying (1) and
longer than $lcs$.\\

In general, given $d$ sequences, there usually exists more than one
LCS of the $d$ sequences. For example, given three sequences $s_1 =
ACTAGTGC$, $s_2 = TGCTAGCA$ and $s_3 = CATGCGAT$, there are two LCSs
with length 4, which are $lcs_1 = CAGC$, $lcs_2 = CTGC$,
respectively. The MLCS problem is to find all LCSs of three or more
sequences. For two sequences, the problem is commonly called the LCS
problem. Obviously, the LCS is a special case of the MLCS. Specific
algorithms developed for LCS are generally inefficient for MLCS.\\


Because of the importance of the MLCS problem, several efficient
algorithms have been proposed in the past decades.

\subsection{Dynamic Programming Based Approaches}
\label{sec:Dynamic Programming}

The classical exact algorithms for MLCS problem are based on dynamic
programming \cite{Smith1981}, \cite{Sankoff1972}. Given $d$ sequences:
$s_1,\, s_2,\,...,\, s_d$ with length $n_1,\, n_2,\, ...,\, n_d$
respectively, these approaches recursively construct a
$n_1 \times n_2 \times ... \times n_d$ dimension score table $T$, in
which $T[i_1,\, i_2,\, ...,\, i_d]$ contains the length of the LCSs of
the prefixes $s_1[1...i_1]$, $s_2[1...i_2]$, ..., $s_d[1...i_d]$.
$T[i_1,\, i_2,\, ...,\, i_d]$ can be computed recursively by the
following formula:

\begin{equation*}
  T[i_1,\, i_2,\, ...,\, i_d] = 
  \begin{cases}
    0 & \text{if $\exists j, 1 \leq j \leq d, i_j = 0$}\\
    T[i_1-1,\, ...,\, i_d-1] + 1  & \text{if $s_1[i_1] = s_2[i_2] =
      ... = s_d[i_d]$}\\
    max(\bar{T}) & \text{otherwise}
  \end{cases}
\end{equation*}

where $\bar{T} = \{T[i_1-1,\, i_2,\, ...,\, i_d],\, T[i_1,\, i_2-1,\,
...,\, i_d],\, ...,\, T[i_1,\, i_2,\, ...,\, i_d-1]\}$. Once the score
table $T$ is constructed, all the MLCS can be collected by tracing
back from the last cell $T[n_1,\, n_2,\, ...,\, n_d]$ to the first
cell $T[0,\, 0,\, ...,\, 0]$. Fig. \ref{fig:DM} shows an example of
score table $T$ for two sequences $s_1 = GATTACA$ and $s_2 =
GTAATCTAAC$.  Obviously, the time and space complexity of dynamic
programming based approaches for a MLCS problem with $d$ sequences of
length $n$ are both $O(n^d)$ \cite{Hsu1984}, therefore, they can not
be applied to MLCS problems with more than two sequences in
practice. To reduce the complexity of dynamic programming based
approaches, various approaches have been proposed
\cite{Hirschberg1977}, \cite{Apostolico1992}, \cite{Masek1980},
\cite{Rick1994}. Unfortunately, these approaches primarily address the
LCS problem of two sequences.

\subsection{Dominant Point Based Approaches}
\label{sec:Dominant Point}

In order to illustrate the dominant point based approaches, we
introduce some terminologies first:

\textbf{Definition 3.} Let $S = \{s_1,\, s_2,\, ...,\, s_d\}$ be a set
of $d$ sequences over $\Sigma$, and $s_i[j]$ be the $j$-th character
of $s_i$. A point $p = (p_1,\, p_2,\, ...,\, p_d)$ is called a
\emph{match point} of $S$, if $s_1[p_1] = s_2[p_2] = ... = s_d[p_d] =
\delta$, where $\delta$ is the symbol corresponding to the matched
point $p$. The character corresponding to the match point $p$ is
denoted as $C(p)$.\\

\textbf{Definition 4.} Given two match points $p = (p_1,\, p_2,\,
...,\, p_d)$ and $q = (q_1,\, q_2,\, ...,\, q_d)$ of $S$, we say that
$p = q$, if and only if $p_i = q_i$ ($1 \leq i \leq d$). If $p_i \leq
q_i$ ($1 \leq i \leq d$), we say $p$ \emph{dominates} $q$, denoted as
$p \preceq q$. Further, if $p_i < q_i$ ($1 \leq i \leq d$), we say $p$
\emph{strongly dominates} $q$, denoted as $p \prec q$.  If $p \prec q$
and there is no match point $r$ such that $p \prec r \prec q$ and
$C(q) = C(r)$, we call $q$ a \emph{successor} of $p$, or $p$ a
\emph{precursor} of $q$. Obviously, one match point has at most
$|\Sigma|$ successors with each character in $\Sigma$ corresponds to
one successor. \\

\textbf{Definition 5.} The \emph{level} of a match point $p = (p_1,\,
p_2,\, ...,\, p_d)$ is defined to be $L(p) = T[p_1,\, p_2,\, ...,\,
p_d]$, where $T$ is the score table constructed in the dynamic
programming methods. A match point $p$ is called a \emph{k-dominant
point} (\emph{k-dominants} for short) if and only if: (1) $L(p) = k$;
(2) there is no other match point $q$ such that: $L(q) = k$ and $q
\preceq q$. All the $k$-dominants forms a set denoted as $D^k$.

The motivation of the dominant point based approaches is to reduce the
time and space complexity of the basic dynamic programming
methods. The key idea is based on the observation that only the
dominant points contributes to the construction of the MLCS. Since the
number of dominant points can be much smaller than that of all cells
in the score table $T$, a dominant point approach that only identifies
the dominant points, without filling the whole score table, can
greatly reduce the time and space complexity.

The search space of the dominant point based approaches can be
organized into a Directed Acyclic Graph (DAG): a node in DAG
represents a match point and an edge $<p,\, q>$ in DAG represents
$p \prec q$ and $L(q) = L(p) + 1$, i.e., $q$ is a successor of $p$. A
node in DAG has at most $|\Sigma|$ successors. Initially, the DAG
contains a source node $(0,\, 0,\, ...,\, 0)$ with no incoming edges
and an end node $(\infty,\, \infty,\, ...,\, \infty)$ with no outgoing
edges, in particular, the end node is defined as the successor of
those nodes without an successor. The DAG can be constructed level by
level as follows: at first, let $k = 0$ (the level), and
$D^0 = \{(0,\, 0,\, ...,\, 0)\}$. Next, with a forward iteration
procedure, the $(k+1)$-dominants $D^{k+1}$ are computed based on the
$k$-dominants $D^k$. Specifically, each node in $D^k$ is expanded by
generating all its $|\Sigma|$ successors first, then an pruning
operation called $Minima$ is performed to identify those successors
who dominants others, and only these dominants are reserved to form
$D^{k+1}$. This procedure is denoted as $D^k \rightarrow D^{k+1}$.
Once all the nodes in DAG have been expanded, the whole DAG is
constructed. In the DAG, a longest path from the source node to the
end node corresponds to a LCS. Thus the MLCS problem becomes finding
all the longest paths from the source node to the end node.The main
drawback of the dominant point based approaches is that the $Minima$
operation needs to compare among the nodes dimension by dimension,
which is very time consuming. Figure shows an example of the dominant
based algorithm processing three sequence.

Hunt \cite{Hunt1977} proposed the first dominant point based algorithm
for two sequences with time complexity $O((r+n)log^n)$, where $r$ is
the number of all nodes in DAG, and $n$ is the length of the two
sequences. Afterwards, to further improve the efficiency, a variety of
dominant point based LCS/MLCS algorithms have been presented. Korkin
\cite{Korkin2001} proposed the first MLCS algorithm with time
complexity $O(|\Sigma|d)$, where $d$ is the number of sequences. Chen
\cite{Chen2006} presented an efficient MLCS algorithm -- FAST-LCS for
DNA sequences, it introduced a novel successor table to obtain the
successors of nodes in constant time and used a pruning operation to
eliminate the non-dominant nodes in each level. Wang \cite{Wang2011}
improved the FAST-MLCS algorithm by using a divide-and-conquer
strategy to eliminate the non-dominant nodes, which is very suitable
for parallelization, it indicates that the parallelized algorithm
Quick-DPPAR has gained a near-linear speedup with respect to its
serial version. It is worth mentioning that Li \cite{Li2012} and Yang
\cite{Yang2010} made attempts to develop efficient parallel algorithms
on GPUs for the LCS problem and on cloud platform for the MLCS
problem, respectively. Unfortunately, Yang \cite{Yang2010} is not
suitable for the general MLCS problem for multiple sequences due to
the large synchronous cost. Recently, Li \cite{LiICDE} and Linear
\cite{LIKDD} proposed two algorithms: PTop-MLCS and RLP-MLCS based on
dominant point, these algorithms used a novel graph model called
Non-redundant Common Subsequence Graph (NCSG) which can greatly reduce
the redundant nodes during processing, and adopt a two-passes
topological sorting procedure to find the MLCS. The authors claimed
that the time complexity of the proposed algorithms is linear to the
number of nodes in NCSG.

For large-scale MLCS problems in practice, the traditional algorithms
usually need a long time and large space to find the optimal solution
(the real MLCS), to address this, approximate algorithms have been
developed to quickly produce a suboptimal solution (partial MLCS) and
gradually improve it when given more time, until an optimal one is
found. Yang \cite{Yang2013} proposed an approximate algorithm Pro-MLCS
and its efficient parallelization based on the dominant point
model. Pro-MLCS can find an approximate solution quickly, which only
takes around 3 percent of the entire running time, and then
progressively generate better solutions until obtaining the optimal
one. Recently, Yang \cite{Yang2014} proposed another two approximate
algorithms SA-MLCS and SLA-MLCS, SA-MLCS uses an iterative beam
widening search strategy to reduce space usage during the iterative
process of finding better solutions. Based on SA-MLCS, SLA-MLCS, a
space-bounded algorithm, is developed to avoid space usage from
exceeding available memory.



\section{Conclusion and Future Works}
\label{sec:conclusion}

In this paper, we propose a Fast Engine for Multi-Pattern Matching
(\textsf{FEMPM}) which includes a filter part and a verification
part. The filter part is used to quickly filter out the positions that
are impossible to match any pattern, while the verification part is
used to verify the potential positions. The verification part used a
data structure called Adaptive Matching Tree (AMT) which can be
constructed to fit the feature of the given pattern set. Owing to the
scalability and compactness of AMT, \textsf{FEMPM} offers a good
support for large-scale pattern sets. Moreover it can improve the
robustness of \textsf{FEMPM} for pattern sets with various $lsp$s. In
the future, we will try to design more efficient inner structures of
the tree nodes.

\section{Acknowledgments}

This work is supported by National Natural Science Foundation of China
(No.61472297) and the Fundamental Research Funds for the Central
Universities (BDZ021430).


\begin{thebibliography}{99}

\bibitem{Smith1981} T.F. Smith and M.S. Waterman, “Identification of
  Common Molecular Subsequences,” J. Molecular Biology, vol. 147,
  pp. 195-197, 1981.

\bibitem{Sankoff1972} D. Sankoff, “Matching Sequences under
Deletion/Insertion Con- straints,” Proc. Nat’l Academy Sciences USA,
vol. 69, pp. 4-6, Jan.  1972.

\bibitem{Hsu1984} W.J. Hsu and M.W. Du, “Computing a Longest Common
  Subsequence for a Set of Strings,” BIT Numerical Math., vol. 24,
  no. 1, pp. 45-59, 1984.

\bibitem{Hirschberg1977} D.S. Hirschberg, “Algorithms for the Longest Common Subse-
quence Problem,” J. ACM, vol. 24, pp. 664-675, 1977

\bibitem{Apostolico1992} A. Apostolico, S. Browne, and C. Guerra,
  “Fast Linear-Space Com- putations of Longest Common Subsequences,”
  Theoretical Com- puter Science, vol. 92, no. 1, pp. 3-17, 1992.

\bibitem{Masek1980} W.J. Masek and M.S. Paterson, “A Faster Algorithm
  Computing String Edit Distances,” J. Computer System Sciences,
  vol. 20, pp. 18- 31, 1980.

\bibitem{Rick1994} C. Rick, “New Algorithms for the Longest Common
  Subsequence Problem,” Technical Report No. 85123-CS, Computer
  Science Dept., Univ. of Bonn, Oct. 1994.
  
\bibitem{Hunt1977} J. W. Hunt and T. G. Szymanski. A fast algorithm
  for computing longest common subsequences.  Communications of the
  ACM, 20(5):350–353, 1977.

\bibitem{Korkin2001} D. Korkin. A new dominant point-based parallel
  algorithm for multiple longest common subsequence problem. Technical
  report, TR01-148, Univ. of New Brunswick, 2001

\bibitem{Chen2006} Y. Chen, A. Wan, and W. Liu. A fast parallel
algorithm for finding the longest common sequence of
multiple biosequences. BMC Bioinformatics, 7(Suppl
4):S4, 2006.

\bibitem{Wang2011} Q. Wang, D. Korkin, and Y. Shang. A fast multiple
longest common subsequence (MLCS) algorithm.  Knowledge and Data
Engineering, IEEE Transactions on, 23(3):321–334, 2011.

\bibitem{Li2012} Y. Li, Y. Wang, and L. Bao. Facc: a novel finite
  automaton based on cloud computing for the multiple longest common
  subsequences search. Mathematical Problems in Engineering, 2012,
  2012.

\bibitem{Yang2013} J. Yang, Y. Xu, and Y. Shang. A new progressive
  algorithm for a multiple longest common subsequences problem and its
  efficient parallelization. Parallel and Distributed Systems, IEEE
  Transactions on, 24(5):862–870, 2013.

\bibitem{Yang2014} J. Yang, Y. Xu, and Y. Shang. A space-bounded
  anytime algorithm for the multiple longest common subsequence
  problem. Knowledge and Data Engineering, Transactions on,
  26(11):2599–2609, 2014.

\bibitem{LiICDE} Yanni Li, Yuping Wang, Zhensong Zhang, etc. A Novel
  Fast and Memory Efficient Parallel MLCS Algorithm for Long and
  Large-Scale Sequences Alignments.  IEEE International Conference on
  Data Engineering (ICDE). pp.1170-1181. 2016.

\bibitem{LiSIGKDD} Li, Yanni and Li, Hui and Duan, Tihua, etc. A Real Linear
and Parallel Multiple Longest Common Subsequences (MLCS)
Algorithm. Proceedings of the 22nd ACM SIGKDD International Conference
on Knowledge Discovery and Data
Mining. pp.1170-1181. pp.1725-1734. 2016.




\bibitem{pizzachil} {\it http://pizzachil.dcc.uchile.cl/}

\end{thebibliography}  


\vspace*{-0.01in}
%\vspace*{-0.3in}
\noindent
\rule{12.6cm}{.1mm}
pp
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
