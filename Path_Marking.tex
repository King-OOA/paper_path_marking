\documentclass{article}


\usepackage{enumerate}

\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{color}
\newcommand{\SWITCH}[1]{\STATE \textbf{switch} (#1)}
\newcommand{\ENDPWITCH}{\STATE \textbf{end switch}}
\newcommand{\CASE}[1]{\STATE \textbf{case} #1\textbf{:} \begin{ALC@g}}
\newcommand{\ENDCASE}{\end{ALC@g}}
\newcommand{\CASELINE}[1]{\STATE \textbf{case} #1\textbf{:} }
\newcommand{\DEFAULT}{\STATE \textbf{default:} \begin{ALC@g}}
\newcommand{\ENDDEFAULT}{\end{ALC@g}}
\newcommand{\DEFAULTLINE}[1]{\STATE \textbf{default:} }
\newtheorem{mydef}{Definition}
\newtheorem{mylm}{Proposition}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}


\begin{document}


\title{A Efficient Exact Algorithm for Multiple Longest Common
  Subsequences (MLCS) Problem Based on Path Marking}

\author{Zhan Peng, Yuping Wang\footnote{Corresponding author}~,}


\maketitle

%begin{history}
%received{(Day Month Year)}
%revised{(Day Month Year)}
%accepted{(Day Month Year)}
%comby{(xxxxxxxxxx)}
%end{history}

\begin{abstract}

  Searching for the Multiple Longest Common Subsequences (MLCS) of
  multiple sequences is a classical NP-hard problem which is widely
  used in many areas such as bioinformatics and biomedicine,
  etc. Although significant efforts have been made to address this
  problem, the increasing amount of biological data requires more
  efficient methods. In this paper, we present a novel fast algorithm
  --- PM-MLCS for the MLCS problem, which is based on the dominant
  point approach and employs a new technique called path
  marking. During the construction of the dominant point graph, the
  path marking technique can real-timely mark the longest path from
  the source node to the current node, and once the graph has been
  constructed the longest paths corresponding to every MLCS can be
  found immediately. The experimental results demonstrate that,
  comparing with the expensive ``Minima'' operation that is widely
  used in the existing algorithms, the path marking is much more
  efficient, and therefore our algorithm is faster than those
  algorithms.

\end{abstract}

\textbf{multiple longest common subsequences (MLCS); Longest common
  subsequence (LCS); dominant point method}

% due to the effectiveness of the filter and the compactness of the AMT
% whether there are patterns starting at that position

\section{Introduction}
\label{sec:introduction}


Many kinds of biological data can be represented as a sequence of
symbols. For instance, proteins [2] are sequences over 20 different
symbols (amino acids), and DNA (genes) can be represented as sequences
over four symbols A, C, G and T corresponding to the four bases.
Measuring the similarity of biological sequences is a fundamental
problem in bioinformatics, which can be used in many applications such
as cancer diagnoses, detection of the species’ common origin [2],
etc. One of the most important ways to measure the similarity of
biological sequences is to find their Multiple Longest Common
Subsequences (MLCS), which has been proved to be an NP-hard problem []
. Traditionally, the works are focusing on either the simplest case of
two sequences, also known as the Longest Common Subsequences (LCS)
problem [24], [36], [39], [45], or the problem’s special case of
three sequences [21], [22]. Although many algorithms have been
proposed for the general case of the problem, they are not very
efficient in practice for large-size problems with many sequences due
to high time and space complexity. Particularly, with the successful
implementation of the human genome project and the development of the
next-generation sequencing techniques, the amount of biological
sequences (as well as other types of sequences from various fields)
are growing explosively [3]. Therefore, it is very important and
valuable to design more efficient MLCS algorithm to process large
amount of biological (and other types) sequences.

In this paper, we proposed a fast algorithm for finding MLCS of many
sequences. Our algorithm is based on the dominant point model, in
which the dominant points produced during processing are organized to
form a Directed Acyclic Graph (DAG), and each of the longest paths
from the source node to the end node corresponds to a MLCS. Different
from the other dominant point based algorithms that using a
time-consuming \emph{Minima} operation to delete the redundant nodes,
and then search for the longest paths from the source node to the end
node to find the MLCS, our method employs a technical called
\emph{path marking}, whenever a node is generated, the longest path
from the source node to the new node is updated immediately, and once
the DAG is constructed, all the MLCS can be found directly from the
end node back to the source node by the marked path. The experiments
shows that the \emph{path marking} technique is much efficient than
the \emph{Minima} operation, so that our algorithm is much faster than
the compared algorithms.

The this paper is organized as follows: Section \ref{sec:related
  works} introduces some preliminaries and reviews the related works
in the MLCS problem. Section \ref{sec:notations} lists the notations
and terminology used in this paper. In section \ref{sec:algorithm},
the our new algorithm is presented in details. In section
\ref{sec:experiments}, experimental results comparing the performances
of the new algorithms with existing ones are presented. In Section
\ref{sec:conclusion} we summarize the paper.

\section{Preliminaries and Related Works}
\label{sec:related works}

In this section, we define some notations and terminology used in this
paper and review some related works in the MLCS problem.

First of all, let $\Sigma$ represent a finite alphabet for the
sequences.  For example, for the DNA sequences,
$\Sigma=\{A, C, T, G\}$.

\textbf{Definition 1.} Let $s=c_1c_2...c_n$ be a sequence of length
$n$ over $\Sigma$, where the $i$-th character of $s$ is denoted by
$s[i]=c_i$. A \emph{subsequence} of $s$ is a sequence that can be
obtained by deleting zero or more (not necessarily consecutive)
characters from $s$. Formally, $s'=c_{i_1}c_{i_2}...c_{i_k}$ is called
a subsequence of $s$, if for $1 \leq j \leq k$, there is
$1 \leq i_j \leq n$, and for all $r$ and $t$, $1 \leq r < t \leq k$,
there is $i_r < i_t$.\\

\textbf{Definition 2.} Given $d$ sequences: $s_1, s_2, ..., s_d$ over
$\Sigma$. A Longest Common Subsequence (\emph{LCS}) of the $d$
sequences is a sequence $lcs$ such that: (1) $lcs$ is a subsequence of
all $s_i$ ($1 \leq i \leq d$) (2) there is no sequence satisfying (1)
and longer than $lcs$.\\

In general, given $d$ sequences, there usually exists more than one
LCS. For example, given three DNA sequences $s_1 = ACTAGTGC$,
$s_2 = TGCTAGCA$ and $s_3 = CATGCGAT$, there are two LCSs of length 4,
which are $lcs_1 = CAGC$ and $lcs_2 = CTGC$, respectively. The MLCS
problem is to find all LCSs of three or more sequences. For the
special case of two sequences, the problem is usually called the LCS
problem. Particularly, specific algorithms developed for LCS problem
are generally inefficient for
MLCS problem.\\

Because of the importance of MLCS problem, several efficient
algorithms have been proposed in the past decades. Roughly, there are
two classes of the MLCS algorithms: the dynamic programming based
approaches and the dominant point based approaches.

\subsection{Dynamic Programming Based Approaches}
\label{sec:Dynamic Programming}

The classical approaches for the MLCS problem are based on dynamic
programming \cite{Smith1981}, \cite{Sankoff1972}. Given $d$ sequences:
$s_1,\, s_2,\,...,\, s_d$ of length $n_1,\, n_2,\, ...,\, n_d$
respectively, these approaches recursively construct a score table $T$
with $n_1 \times n_2 \times ... \times n_d$ cells, in which
$T[i_1,\, i_2,\, ...,\, i_d]$ records the length of the LCSs of the
prefixes $s_1[1...i_1]$, $s_2[1...i_2]$, ..., $s_d[1...i_d]$, and
$T[i_1,\, i_2,\, ...,\, i_d]$ can be computed recursively by the
following formula:

\begin{equation*}
  T[i_1,\, i_2,\, ...,\, i_d] = 
  \begin{cases}
    0 & \text{if $\exists j(1 \leq j \leq d), i_j = 0$}\\
    T[i_1-1,\, ...,\, i_d-1] + 1  & \text{if $s_1[i_1] = s_2[i_2] =
      ... = s_d[i_d]$}\\
    max(\bar{T}) & \text{otherwise}
  \end{cases}
\end{equation*}

where $\bar{T} = \{T[i_1-1,\, i_2,\, ...,\, i_d],\, T[i_1,\, i_2-1,\,
...,\, i_d],\, ...,\, T[i_1,\, i_2,\, ...,\, i_d-1]\}$. Once the score
table $T$ is constructed, the MLCS can be collected by tracing back
from the last cell $T[n_1,\, n_2,\, ...,\, n_d]$ to the first cell
$T[0,\, 0,\, ...,\, 0]$. Fig. \ref{fig:DM} (a) shows an example of the
score table $T$ for two sequences $s_1 = ACTAGCTA$ and $s_2 =
TCAGGTAT$. Their MLCS are $TAGTA$ and $CAGTA$ which can be found by
tracing back from $T[8,\, 8]$ to $T[0,\, 0]$, as shown in Fig. [] (b).


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\textwidth]{./eps/DM}
  \caption{The score table of two DNA sequences ACTAGCTA and TCAGGTAT.}
  \label{fig:DM}
\end{figure}

Obviously, the time and space complexity of dynamic programming based
approaches for a MLCS problem with $d$ sequences of length $n$ are
both $O(n^d)$ \cite{Hsu1984}, therefore, those approaches can not be
applied to MLCS problems with more than two sequences in practice. To
reduce the complexity of dynamic programming based approaches, various
methods have been proposed \cite{Hirschberg1977},
\cite{Apostolico1992}, \cite{Masek1980},
\cite{Rick1994}. Unfortunately, these methods primarily address the
LCS problem of two sequences.

\subsection{Dominant Point Based Approaches}
\label{sec:Dominant Point}

Many works have been proposed to improve dynamic programming based
approaches in order to process large size data, among which the
dominant point approaches are the most efficient. Before introducing
the dominant point based approaches, some terminologies are introduced
first:

\textbf{Definition 3.} Given $d$ sequences: $s_1,\, s_2,\, ...,\, s_d$
over $\Sigma$. A point $p = (p_1,\, p_2,\, ...,\, p_d)$ is called a
\emph{match point} of the sequences, if $s_1[p_1] = s_2[p_2] = ... =
s_d[p_d] = \delta$, where $\delta$ is the character corresponding to
the matched point $p$ and denoted by $C(p)$.\\

\textbf{Definition 4.} Given two match points $p = (p_1,\, p_2,\,
...,\, p_d)$ and $q = (q_1,\, q_2,\, ...,\, q_d)$ of $d$ sequences, we
say that $p = q$, if and only if $p_i = q_i$ ($1 \leq i \leq d$). If
$p_i \leq q_i$ ($1 \leq i \leq d$), we say $p$ \emph{dominates} $q$,
denoted by $p \preceq q$. Further, if $p_i < q_i$ ($1 \leq i \leq d$),
we say $p$ \emph{strongly dominates} $q$, denoted by $p \prec q$.  If
$p \prec q$ and there is no match point $r$ such that $p \prec r \prec
q$ and $C(q) = C(r)$, we call $q$ a \emph{successor} of $p$, or $p$ a
\emph{precursor} of $q$. In particular, one match point has at most
$|\Sigma|$ successors with each character in $\Sigma$ corresponds to
one successor. \\

\textbf{Definition 5.} The \emph{level} of a match point $p = (p_1,\,
p_2,\, ...,\, p_d)$ is defined to be $L(p) = T[p_1,\, p_2,\, ...,\,
p_d]$, where $T$ is the score table constructed by formula []. A match
point $p$ is called a \emph{k-dominant point} (\emph{k-dominants} for
short) if and only if: (1) $L(p) = k$ (2) there is no other match
point $q$ such that: $L(q) = k$ and $q \preceq q$. All the
$k$-dominants form a set denoted by $D^k$.

The motivation of the dominant point based approaches is to reduce the
time and space complexity of the basic dynamic programming
methods. The key idea is based on the observation that only the
dominant points contributes to the construction of the MLCS (as shown
in Fig \ref{fig:DM} (b), the shaded cells correspond to the dominant
points).  Since the number of dominant points can be much smaller than
that of all cells in the score table $T$, a dominant point approach
that only identifies the dominant points, without filling the whole
score table, can greatly reduce the time and space complexity.

The search space of the dominant point based approaches can be
organized into a Directed Acyclic Graph (DAG): a node in DAG
represents a match point and an edge $\langle p,\, q \rangle$ in DAG
represents $p \prec q$ and $L(q) = L(p) + 1$, i.e., $q$ is a successor
of $p$. Particularly, a node in DAG has at most $|\Sigma|$
successors. Initially, the DAG contains a \emph{source node}
$(0,\, 0,\, ...,\, 0)$ with no incoming edges and an \emph{end node}
$(\infty,\, \infty,\, ...,\, \infty)$ with no outgoing edges, in
particular, the end node is defined as the successor of those nodes
without an successor. The DAG can be constructed level by level as
follows: at first, let the level $k = 0$, and
$D^0 = \{(0,\, 0,\, ...,\, 0)\}$. Next, with a forward iteration
procedure, the $(k+1)$-dominants $D^{k+1}$ are computed based on the
$k$-dominants $D^k$, and this procedure is denoted as
$D^k \rightarrow D^{k+1}$. Specifically, each node in $D^k$ is
expanded by generating all its $|\Sigma|$ successors, then an pruning
operation called $Minima$ is performed to identify those successors
who dominant others, and only those dominants are reserved and form
$D^{k+1}$. Once all the nodes in DAG have been expanded, the whole DAG
is constructed. In the DAG, a longest path from the source node to the
end node corresponds to a LCS, and thus, the MLCS problem becomes
finding all the longest paths from the source node to the end node.
Fig.  \ref{fig:DAG} shows the DAG constructed by the general dominant
based algorithms for the same two DNA sequences shown in
Fig. \ref{fig:DM}. The black nodes in the DAG are generated repeatedly
while the gray nodes in each level are non-dominant points, and both
of these nodes will be eliminated by the \emph{Minima} operation. The
main drawback of the dominant point based approaches is that a lot of
redundant nodes will be generated and the \emph{Minima} operation
needs to compare among the match points dimension by dimension, which
is very time consuming.


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.6\textwidth]{./eps/DAG}
  \caption{The DAG constructed by the general dominant point based
    algorithms for two sequences ACTAGCTA and TCAGGTAT, in which the
    black and gray nodes will be eliminated by the \emph{Minima}
    operation.}
  \label{fig:DAG}
\end{figure}

Hunt \cite{Hunt1977} proposed the first dominant point based algorithm
for two sequences with time complexity $O((r+n)log^n)$, where $r$ is
the number of nodes in DAG, and $n$ is the length of the two
sequences. Afterwards, to further improve the efficiency, a variety of
dominant point based LCS/MLCS algorithms have been presented. Korkin
\cite{Korkin2001} proposed the first parallel MLCS algorithm with time
complexity $O(|\Sigma|d)$, where $d$ is the number of sequences. Chen
\cite{Chen2006} presented an efficient MLCS algorithm -- FAST-LCS for
DNA sequences, it introduced a novel data structure called successor
table to obtain the successors of nodes in constant time and used a
pruning operation to eliminate the non-dominant nodes in each
level. Wang \cite{Wang2011} improved the FAST-MLCS algorithm by using
a divide-and-conquer strategy to eliminate the non-dominant nodes,
which is very suitable for parallelization, it indicated that the
parallelized algorithm Quick-DPPAR had gained a near-linear speedup
compared to its serial version. Li \cite{Li2012} and Yang
\cite{Yang2010} made efforts to develop efficient parallel algorithms
on GPUs for the LCS problem and on cloud platform for the MLCS
problem, respectively. Unfortunately, Yang \cite{Yang2010} is not
suitable for the MLCS problem with multiple sequences due to the large
synchronous costs. Recently, Li \cite{LiICDE} and Li \cite{LiSIGKDD}
proposed two algorithms: PTop-MLCS and RLP-MLCS based on dominant
points, these algorithms used a novel graph model called Non-redundant
Common Subsequence Graph (NCSG) which can greatly reduce the redundant
nodes during processing, and adopted a two-passes topological sorting
procedure to find the MLCS. The authors claimed that the time
complexity of their algorithms is linear with respect to the number of
nodes in NCSG.

In practice, for MLCS problems with multiple sequences, the
traditional algorithms usually need a long time and large space to
find the optimal solution (the real MLCS), to address this,
approximate algorithms have been developed to quickly produce a
suboptimal solution (partial MLCS) and gradually improve it when given
more time, until an optimal one is found. Yang \cite{Yang2013}
proposed an approximate algorithm Pro-MLCS as well as its efficient
parallelization based on the dominant point model. Pro-MLCS can find
an approximate solution quickly, which only takes around 3 percent of
the entire running time, and then progressively generate better
solutions until obtaining the optimal one. Recently, Yang
\cite{Yang2014} proposed another two approximate algorithms SA-MLCS
and SLA-MLCS. SA-MLCS used an iterative beam widening search strategy
to reduce space usage during the iterative process of finding better
solutions. Based on SA-MLCS, SLA-MLCS, a space-bounded algorithm, is
developed to avoid space usage from exceeding available memory.


\section{PM-MLCS: A New Fast MLCS Algorithm}
\label{sec:PM-MLCS}


\section{Conclusion and Future Works}
\label{sec:conclusion}

In this paper, we propose a Fast Engine for Multi-Pattern Matching
(\textsf{FEMPM}) which includes a filter part and a verification
part. The filter part is used to quickly filter out the positions that
are impossible to match any pattern, while the verification part is
used to verify the potential positions. The verification part used a
data structure called Adaptive Matching Tree (AMT) which can be
constructed to fit the feature of the given pattern set. Owing to the
scalability and compactness of AMT, \textsf{FEMPM} offers a good
support for large-scale pattern sets. Moreover it can improve the
robustness of \textsf{FEMPM} for pattern sets with various $lsp$s. In
the future, we will try to design more efficient inner structures of
the tree nodes.

\section{Acknowledgments}

This work is supported by National Natural Science Foundation of China
(No.61472297) and the Fundamental Research Funds for the Central
Universities (BDZ021430).


\begin{thebibliography}{99}

\bibitem{Smith1981} T.F. Smith and M.S. Waterman, “Identification of
  Common Molecular Subsequences,” J. Molecular Biology, vol. 147,
  pp. 195-197, 1981.

\bibitem{Sankoff1972} D. Sankoff, “Matching Sequences under
Deletion/Insertion Con- straints,” Proc. Nat’l Academy Sciences USA,
vol. 69, pp. 4-6, Jan.  1972.

\bibitem{Hsu1984} W.J. Hsu and M.W. Du, “Computing a Longest Common
  Subsequence for a Set of Strings,” BIT Numerical Math., vol. 24,
  no. 1, pp. 45-59, 1984.

\bibitem{Hirschberg1977} D.S. Hirschberg, “Algorithms for the Longest Common Subse-
quence Problem,” J. ACM, vol. 24, pp. 664-675, 1977

\bibitem{Apostolico1992} A. Apostolico, S. Browne, and C. Guerra,
  “Fast Linear-Space Com- putations of Longest Common Subsequences,”
  Theoretical Com- puter Science, vol. 92, no. 1, pp. 3-17, 1992.

\bibitem{Masek1980} W.J. Masek and M.S. Paterson, “A Faster Algorithm
  Computing String Edit Distances,” J. Computer System Sciences,
  vol. 20, pp. 18- 31, 1980.

\bibitem{Rick1994} C. Rick, “New Algorithms for the Longest Common
  Subsequence Problem,” Technical Report No. 85123-CS, Computer
  Science Dept., Univ. of Bonn, Oct. 1994.
  
\bibitem{Hunt1977} J. W. Hunt and T. G. Szymanski. A fast algorithm
  for computing longest common subsequences.  Communications of the
  ACM, 20(5):350–353, 1977.

\bibitem{Korkin2001} D. Korkin. A new dominant point-based parallel
  algorithm for multiple longest common subsequence problem. Technical
  report, TR01-148, Univ. of New Brunswick, 2001

\bibitem{Chen2006} Y. Chen, A. Wan, and W. Liu. A fast parallel
algorithm for finding the longest common sequence of
multiple biosequences. BMC Bioinformatics, 7(Suppl
4):S4, 2006.

\bibitem{Wang2011} Q. Wang, D. Korkin, and Y. Shang. A fast multiple
longest common subsequence (MLCS) algorithm.  Knowledge and Data
Engineering, IEEE Transactions on, 23(3):321–334, 2011.

\bibitem{Li2012} Y. Li, Y. Wang, and L. Bao. Facc: a novel finite
  automaton based on cloud computing for the multiple longest common
  subsequences search. Mathematical Problems in Engineering, 2012,
  2012.

\bibitem{Yang2010} J. Yang, Y. Xu, and Y. Shang. An efficient parallel
  algorithm for longest common subsequence problem on GPUs. In
  Proceedings of the World Congress on Engineering, volume 1, pp.
  499–504, 2010.

\bibitem{Yang2013} J. Yang, Y. Xu, and Y. Shang. A new progressive
  algorithm for a multiple longest common subsequences problem and its
  efficient parallelization. Parallel and Distributed Systems, IEEE
  Transactions on, 24(5):862–870, 2013.

\bibitem{Yang2014} J. Yang, Y. Xu, and Y. Shang. A space-bounded
  anytime algorithm for the multiple longest common subsequence
  problem. Knowledge and Data Engineering, Transactions on,
  26(11):2599–2609, 2014.

\bibitem{LiICDE} Yanni Li, Yuping Wang, Zhensong Zhang, etc. A Novel
  Fast and Memory Efficient Parallel MLCS Algorithm for Long and
  Large-Scale Sequences Alignments.  IEEE International Conference on
  Data Engineering (ICDE). pp.1170-1181. 2016.

\bibitem{LiSIGKDD} Li, Yanni and Li, Hui and Duan, Tihua, etc. A Real Linear
and Parallel Multiple Longest Common Subsequences (MLCS)
Algorithm. Proceedings of the 22nd ACM SIGKDD International Conference
on Knowledge Discovery and Data
Mining. pp.1170-1181. pp.1725-1734. 2016.




\bibitem{pizzachil} {\it http://pizzachil.dcc.uchile.cl/}

\end{thebibliography}  


\vspace*{-0.01in}
%\vspace*{-0.3in}
\noindent
\rule{12.6cm}{.1mm}
pp
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
